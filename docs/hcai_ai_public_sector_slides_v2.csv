Slide #,Slide Title,Themes,Hook,Key Quotes / Bullets,Takeaways,Source
1,119th HCAI Note,"chatbot UX, governance, risks, verification",“The ethics board never had a second meeting.”,"The people who were most afraid of the risks of AI decided they should be the ones to build it. Then distrust fueled a spiraling competition. • AI is a result of human design decisions; responsibility and liability belong to developers and firms. • Adopt independent oversight, audit trails, user control panels, continuous monitoring, and public incident reporting. • 'The Lost Ethics Board' reveals failure to mitigate harms — 'The ethics board never had a second meeting.' • Human supervisory controls can operate at different timescales; speed is not an excuse to remove accountability. • Mars Rovers show human-in-charge improves reliability and creativity; that's HCAI in practice.",Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/18e118214ce223bc
2,118th HCAI Note,"economics, governance, risks, verification",Dennis Yi Tenen’s 'Literary Theory for Robots'; 'great art remains human'; AI is collective labor; N,"Great art, like great cuisine, will always remain the purview of exceptional talent. • AI is collective labor; intelligence is distributed — metaphors should not obscure responsibility. • Machines alone cannot become moral agents — responsibility remains with people and institutions. • National Academies workshops on Human & Organizational Factors in AI Risk Management complement NIST AI RMF. • Human operators seize unpredicted opportunities and handle failures — human control yields safer, more reliable systems.",Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/18dca0c0cad095f8
3,116th HCAI Note,"chatbot UX, governance, risks",Community replies: 'supertools' over AGI; social reasoning matters; nudge better ethical reasoning; ,"Prefer 'supertools' that amplify/augment human abilities over AGI fantasies. • AI often ignores talk-in-interaction and everyday reasoning; study AI-in-the-world. • Use AI to prompt better human reasoning in-task — not because AI thinks better, but to support values and judgment. • Without HCAI guardrails, AGI will serve the few; socio-technical history shows human guardrails improve reliability. • Webinar: Linking STS Organization Design and HCAI — bridging safety practices and org design.",Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/18c464d68d6b4d26
4,117th HCAI Note,governance,Jason Farago essay; critique of 'inevitability' framing; focus on design choices and human-centered ,Challenge 'inevitability' narratives; design choices shape outcomes. • Bring broader voices and evidence from 'AI-in-the-world' rather than benchmark myopia. • Use HCAI framing to connect cultural analysis with practical controls and accountability.,Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/18cea48745c8e03d
5,115th HCAI Note,verification,"Smart enough for trivia, dumb enough to toast in a bathtub.","AI can be incredibly smart and shockingly stupid — design for limits. • Favor practical controls, verification, and value-aligned objectives over hype. • Educators should teach evaluation, sourcing, and reasoning with AI as a tool.",Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/18c18ae58d286301
6,HCAI Note (encoding),governance,Design for responsibility; audits; oversight.,Assign accountable owners; define escalation paths and review cadence. • Publish incidents and change logs; require independent review.,Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/18bb147f69ca8165
7,HCAI Note (encoding),verification,"Verification, evaluation, building user trust.",Specify testable claims; collect evidence; maintain audit trails. • Match evaluation scope and certainty to domain constraints.,Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/18b966026dbd3a83
8,HCAI Note (encoding),governance,Governance and public reporting of incidents.,Assign accountable owners; define escalation paths and review cadence. • Publish incidents and change logs; require independent review.,Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/1887480bc8c5b0d1
9,HCAI Note (encoding),economics,Economics of AI and the relationship economy.,Align incentives; avoid growth hacks that erode reliability.,Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/1884f2cd8cdfe1dc
10,HCAI Note (encoding),chatbot UX,Chatbot UX and human-in-the-loop controls.,Use control panels/faceted prompts; avoid vague 'How can I help?'. • Expose limits and sources; offer safer alternatives.,Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/187e468166c11818
11,HCAI Note (encoding),"governance, verification",Verification and audit trails in critical systems.,Assign accountable owners; define escalation paths and review cadence. • Publish incidents and change logs; require independent review. • Specify testable claims; collect evidence; maintain audit trails. • Match evaluation scope and certainty to domain constraints.,Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/187543cb904e9816
12,HCAI Note (encoding),"economics, risks, verification",Risk management workshops; NIST AI RMF alignment.,Specify testable claims; collect evidence; maintain audit trails. • Match evaluation scope and certainty to domain constraints. • Map failure modes; plan mitigations; practice rollback/kill-switch. • Align incentives; avoid growth hacks that erode reliability.,Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/187303348aa1434f
13,HCAI Note (encoding),governance,“The ethics board never had a second meeting.”,Assign accountable owners; define escalation paths and review cadence. • Publish incidents and change logs; require independent review.,Design for human control; align with AI RMF; verify claims with evidence; avoid hype; center users.,https://mail.google.com/mail/#all/1870c412016892b4
